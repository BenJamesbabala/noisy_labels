{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "FN = 'mnist-simple'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook works with Keras version 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook we:\n",
    "* train a on MNIST in which the training labels are scrambled by a fixed permutation 46% of the time\n",
    "* The baseline 3 layer MLP model gives an accuracy of 74% on MNIST test set which was not scrambled\n",
    "* The confusion matrix of the noisy training data is computed\n",
    "* We then add a customized Keras layer ([Channel](./channel.py)) to model the noise. This layer is initialized with the log of the confusion matrix (`channel_weights`):\n",
    "```python\n",
    "channeled_output = Channel(name='channel',weights=[channel_weights])(baseline_output)\n",
    "```\n",
    "* We continue training on the new output (`channeled_output`)\n",
    "* The baseline output (`baseline_output`) has now an accuracy of 98%.\n",
    "\n",
    "For more information see the description of the [simple noise adaptation layer in the paper](https://openreview.net/forum?id=H12GRgcxg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import numpy as np\n",
    "import random\n",
    "seed = 42\n",
    "np.random.seed(seed)  # for reproducibility\n",
    "random.seed(seed)\n",
    "verbose = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# in case you dont have a GPU\n",
    "import os\n",
    "os.environ['THEANO_FLAGS'] = 'device=cpu,floatX=float32'  # Use CPU on Theano\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = ''  # Disable GPU usage on tensorflow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "nb_classes = 10 # number of categories we classify. MNIST is 10 digits\n",
    "# input image dimensions. In CNN we think we have a \"color\" image with 1 channel of color.\n",
    "# in MLP with flatten the pixels to img_rows*img_cols\n",
    "img_color, img_rows, img_cols = 1, 28, 28\n",
    "img_size = img_color*img_rows*img_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using Theano backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MNIST training data set label distribution [5923 6742 5958 6131 5842 5421 5918 6265 5851 5949]\n",
      "test distribution [ 980 1135 1032 1010  982  892  958 1028  974 1009]\n"
     ]
    }
   ],
   "source": [
    "from keras.datasets import mnist\n",
    "# keras has a built in tool that download the MNIST data set for you to `~/.keras/datasets/`\n",
    "# the data, shuffled and split between train and test sets\n",
    "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
    "print('MNIST training data set label distribution', np.bincount(y_train))\n",
    "print('test distribution', np.bincount(y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape: (60000, 784)\n",
      "60000 train samples\n",
      "10000 test samples\n"
     ]
    }
   ],
   "source": [
    "X_train = X_train.reshape(X_train.shape[0], img_size)\n",
    "X_test = X_test.reshape(X_test.shape[0], img_size)\n",
    "    \n",
    "X_train = X_train.astype('float32')\n",
    "X_test = X_test.astype('float32')\n",
    "X_train /= 255.\n",
    "X_test /= 255.\n",
    "print('X_train shape:', X_train.shape)\n",
    "print(X_train.shape[0], 'train samples')\n",
    "print(X_test.shape[0], 'test samples')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## noisy labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "NOISE_LEVEL=0.46  # what part of training labels are permuted\n",
    "perm = np.array([7, 9, 0, 4, 2, 1, 3, 5, 6, 8])  # noise permutation (from Reed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "noise = perm[y_train]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# replace some of the training labels with permuted (noise) labels.\n",
    "# make sure each categories receive an equal amount of noise\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "_, noise_idx = next(iter(StratifiedShuffleSplit(n_splits=1,\n",
    "                                                test_size=NOISE_LEVEL,\n",
    "                                                random_state=seed).split(X_train,y_train)))\n",
    "y_train_noise = y_train.copy()\n",
    "y_train_noise[noise_idx] = noise[noise_idx]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "actual noise level"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.45999999999999996"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1. - np.mean(y_train_noise == y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "split training data to training and validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# break the training set to 10% validation which we will use for early stopping.\n",
    "train_idx, val_idx = next(iter(\n",
    "        StratifiedShuffleSplit(n_splits=1, test_size=0.1,\n",
    "                               random_state=seed).split(X_train, y_train_noise)))\n",
    "X_train_train = X_train[train_idx]\n",
    "y_train_train = y_train_noise[train_idx]\n",
    "X_train_val = X_train[val_idx]\n",
    "y_train_val = y_train_noise[val_idx]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## baseline model\n",
    "We use the `Sequential` model from keras\n",
    "[mlp example](https://github.com/fchollet/keras/blob/master/examples/mnist_mlp.py)\n",
    "as a single layer which computes the last hidden layer which we then use to\n",
    "compute the baseline and as an input to the channel matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "nhiddens = [500, 300]\n",
    "DROPOUT=0.5\n",
    "opt='adam'\n",
    "batch_size = 256\n",
    "patience = 4  # Early stopping patience\n",
    "epochs = 40  # number of epochs to train on"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "hidden_layers = Sequential(name='hidden')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from keras.layers import Dense, Dropout, Activation\n",
    "for i, nhidden in enumerate(nhiddens):\n",
    "    hidden_layers.add(Dense(nhidden,\n",
    "                            input_shape=(img_size,) if i == 0 else []))\n",
    "    hidden_layers.add(Activation('relu'))\n",
    "    hidden_layers.add(Dropout(DROPOUT))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from keras.layers import Input\n",
    "train_inputs = Input(shape=(img_size,))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "last_hidden = hidden_layers(train_inputs)\n",
    "baseline_output = Dense(nb_classes, activation='softmax', name='baseline')(last_hidden)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from keras.models import Model\n",
    "model = Model(inputs=train_inputs, outputs=baseline_output)\n",
    "model.compile(loss='sparse_categorical_crossentropy',\n",
    "              optimizer=opt,\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "baseline model performance evaluation before training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def eval(model,y_test=y_test):\n",
    "    return dict(zip(model.metrics_names,model.evaluate(X_test,y_test, verbose=False)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'acc': 0.090800000000000006, 'loss': 2.3604063068389891}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### baseline training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 54000 samples, validate on 6000 samples\n",
      "Epoch 1/40\n",
      "54000/54000 [==============================] - 5s - loss: 1.2561 - acc: 0.4230 - val_loss: 0.9025 - val_acc: 0.4867\n",
      "Epoch 2/40\n",
      "54000/54000 [==============================] - 5s - loss: 0.9392 - acc: 0.4828 - val_loss: 0.8409 - val_acc: 0.4802\n",
      "Epoch 3/40\n",
      "54000/54000 [==============================] - 5s - loss: 0.8770 - acc: 0.4946 - val_loss: 0.8118 - val_acc: 0.4882\n",
      "Epoch 4/40\n",
      "54000/54000 [==============================] - 5s - loss: 0.8451 - acc: 0.5004 - val_loss: 0.7988 - val_acc: 0.4955\n",
      "Epoch 5/40\n",
      "54000/54000 [==============================] - 5s - loss: 0.8223 - acc: 0.5076 - val_loss: 0.7839 - val_acc: 0.5108\n",
      "Epoch 6/40\n",
      "54000/54000 [==============================] - 7s - loss: 0.8083 - acc: 0.5104 - val_loss: 0.7804 - val_acc: 0.5142\n",
      "Epoch 7/40\n",
      "54000/54000 [==============================] - 6s - loss: 0.7934 - acc: 0.5117 - val_loss: 0.7715 - val_acc: 0.5088\n",
      "Epoch 8/40\n",
      "54000/54000 [==============================] - 6s - loss: 0.7865 - acc: 0.5156 - val_loss: 0.7674 - val_acc: 0.5110\n",
      "Epoch 9/40\n",
      "54000/54000 [==============================] - 6s - loss: 0.7747 - acc: 0.5219 - val_loss: 0.7618 - val_acc: 0.5247\n",
      "Epoch 10/40\n",
      "54000/54000 [==============================] - 7s - loss: 0.7710 - acc: 0.5217 - val_loss: 0.7645 - val_acc: 0.5055\n",
      "Epoch 11/40\n",
      "54000/54000 [==============================] - 6s - loss: 0.7651 - acc: 0.5260 - val_loss: 0.7591 - val_acc: 0.5098\n",
      "Epoch 12/40\n",
      "54000/54000 [==============================] - 5s - loss: 0.7622 - acc: 0.5225 - val_loss: 0.7640 - val_acc: 0.5073\n",
      "Epoch 13/40\n",
      "54000/54000 [==============================] - 5s - loss: 0.7567 - acc: 0.5248 - val_loss: 0.7605 - val_acc: 0.5068\n",
      "Epoch 14/40\n",
      "54000/54000 [==============================] - 5s - loss: 0.7528 - acc: 0.5286 - val_loss: 0.7569 - val_acc: 0.5098\n",
      "Epoch 15/40\n",
      "54000/54000 [==============================] - 5s - loss: 0.7468 - acc: 0.5320 - val_loss: 0.7617 - val_acc: 0.5068\n",
      "Epoch 16/40\n",
      "54000/54000 [==============================] - 6s - loss: 0.7450 - acc: 0.5315 - val_loss: 0.7552 - val_acc: 0.5198\n",
      "Epoch 17/40\n",
      "54000/54000 [==============================] - 5s - loss: 0.7418 - acc: 0.5354 - val_loss: 0.7615 - val_acc: 0.5052\n",
      "Epoch 18/40\n",
      "54000/54000 [==============================] - 5s - loss: 0.7385 - acc: 0.5365 - val_loss: 0.7601 - val_acc: 0.5172\n",
      "Epoch 19/40\n",
      "54000/54000 [==============================] - 5s - loss: 0.7382 - acc: 0.5353 - val_loss: 0.7578 - val_acc: 0.5050\n",
      "Epoch 20/40\n",
      "54000/54000 [==============================] - 6s - loss: 0.7361 - acc: 0.5364 - val_loss: 0.7606 - val_acc: 0.5040\n",
      "Epoch 21/40\n",
      "54000/54000 [==============================] - 6s - loss: 0.7313 - acc: 0.5417 - val_loss: 0.7623 - val_acc: 0.5045\n",
      "Epoch 00020: early stopping\n"
     ]
    }
   ],
   "source": [
    "from keras.callbacks import EarlyStopping\n",
    "train_res = model.fit(X_train_train,\n",
    "                      y_train_train,\n",
    "                      batch_size=batch_size,\n",
    "                      epochs=epochs,\n",
    "                      verbose=verbose,\n",
    "                      validation_data=(X_train_val,\n",
    "                                       y_train_val),\n",
    "                      callbacks=\n",
    "                      [EarlyStopping(patience=patience,mode='min',\n",
    "                                     verbose=verbose)]\n",
    "                      )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### baseline performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'acc': 0.74380000000000002, 'loss': 0.68568477287292484}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# build confusion matrix (prediction,noisy_label)\n",
    "ybaseline_predict = model.predict(X_train,batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000,)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ybaseline_predict = np.argmax(ybaseline_predict, axis=-1)\n",
    "ybaseline_predict.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "baseline_confusion = np.zeros((nb_classes, nb_classes))\n",
    "for n, p in zip(y_train_noise, ybaseline_predict):\n",
    "    baseline_confusion[p, n] += 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYYAAAEdCAYAAAAIIcBlAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nESmwGIiISOH/AbSo10m3R8K5AAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x12d647cd0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "# perm_bias_weights.astype(int)\n",
    "plt.pcolor(baseline_confusion)\n",
    "plt.ylabel('true labels')\n",
    "plt.xlabel('baseline labels')\n",
    "plt.title('baseline confusion matrix');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simple channel model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# ignore baseline loss in training\n",
    "BETA = 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "channel_weights = baseline_confusion.copy()\n",
    "channel_weights /= channel_weights.sum(axis=1, keepdims=True)\n",
    "# perm_bias_weights[prediction,noisy_label] = log(P(noisy_label|prediction))\n",
    "channel_weights = np.log(channel_weights + 1e-8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# If you dont have a pre-trained baseline model then use this\n",
    "# channel_weights = (\n",
    "#     np.array([[np.log(1. - NOISE_LEVEL)\n",
    "#                         if i == j else\n",
    "#                         np.log(NOISE / (nb_classes - 1.))\n",
    "#                         for j in range(nb_classes)] for i in\n",
    "#               range(nb_classes)])\n",
    "#     + 0.01 * np.random.random((nb_classes, nb_classes)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from channel import Channel\n",
    "channeled_output = Channel(name='channel',weights=[channel_weights])(baseline_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "simple_model = Model(inputs=train_inputs, outputs=[channeled_output, baseline_output])\n",
    "simple_model.compile(loss='sparse_categorical_crossentropy',loss_weights=[1.-BETA, BETA],\n",
    "              optimizer=opt,\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 54000 samples, validate on 6000 samples\n",
      "Epoch 1/40\n",
      "54000/54000 [==============================] - 5s - loss: 0.8482 - channel_loss: 0.8482 - baseline_loss: 1.8758 - channel_acc: 0.5312 - baseline_acc: 0.5292 - val_loss: 0.8508 - val_channel_loss: 0.8508 - val_baseline_loss: 2.1850 - val_channel_acc: 0.5222 - val_baseline_acc: 0.5188\n",
      "Epoch 2/40\n",
      "54000/54000 [==============================] - 5s - loss: 0.8203 - channel_loss: 0.8203 - baseline_loss: 2.4552 - channel_acc: 0.5360 - baseline_acc: 0.5316 - val_loss: 0.8354 - val_channel_loss: 0.8354 - val_baseline_loss: 2.6793 - val_channel_acc: 0.5283 - val_baseline_acc: 0.5233\n",
      "Epoch 3/40\n",
      "54000/54000 [==============================] - 5s - loss: 0.8058 - channel_loss: 0.8058 - baseline_loss: 2.7526 - channel_acc: 0.5371 - baseline_acc: 0.5324 - val_loss: 0.8192 - val_channel_loss: 0.8192 - val_baseline_loss: 2.8539 - val_channel_acc: 0.5193 - val_baseline_acc: 0.5217\n",
      "Epoch 4/40\n",
      "54000/54000 [==============================] - 6s - loss: 0.7912 - channel_loss: 0.7912 - baseline_loss: 3.0094 - channel_acc: 0.5386 - baseline_acc: 0.5341 - val_loss: 0.8089 - val_channel_loss: 0.8089 - val_baseline_loss: 3.1643 - val_channel_acc: 0.5215 - val_baseline_acc: 0.5203\n",
      "Epoch 5/40\n",
      "54000/54000 [==============================] - 6s - loss: 0.7844 - channel_loss: 0.7844 - baseline_loss: 3.1881 - channel_acc: 0.5378 - baseline_acc: 0.5336 - val_loss: 0.8042 - val_channel_loss: 0.8042 - val_baseline_loss: 3.3561 - val_channel_acc: 0.5220 - val_baseline_acc: 0.5210\n",
      "Epoch 6/40\n",
      "54000/54000 [==============================] - 5s - loss: 0.7759 - channel_loss: 0.7759 - baseline_loss: 3.3692 - channel_acc: 0.5403 - baseline_acc: 0.5366 - val_loss: 0.7992 - val_channel_loss: 0.7992 - val_baseline_loss: 3.3789 - val_channel_acc: 0.5282 - val_baseline_acc: 0.5287\n",
      "Epoch 7/40\n",
      "54000/54000 [==============================] - 5s - loss: 0.7702 - channel_loss: 0.7702 - baseline_loss: 3.4380 - channel_acc: 0.5391 - baseline_acc: 0.5362 - val_loss: 0.7987 - val_channel_loss: 0.7987 - val_baseline_loss: 3.6381 - val_channel_acc: 0.5272 - val_baseline_acc: 0.5257\n",
      "Epoch 8/40\n",
      "54000/54000 [==============================] - 5s - loss: 0.7685 - channel_loss: 0.7685 - baseline_loss: 3.5656 - channel_acc: 0.5396 - baseline_acc: 0.5368 - val_loss: 0.7980 - val_channel_loss: 0.7980 - val_baseline_loss: 3.6580 - val_channel_acc: 0.5202 - val_baseline_acc: 0.5200\n",
      "Epoch 9/40\n",
      "54000/54000 [==============================] - 5s - loss: 0.7639 - channel_loss: 0.7639 - baseline_loss: 3.6116 - channel_acc: 0.5402 - baseline_acc: 0.5376 - val_loss: 0.7965 - val_channel_loss: 0.7965 - val_baseline_loss: 3.7177 - val_channel_acc: 0.5227 - val_baseline_acc: 0.5210\n",
      "Epoch 10/40\n",
      "54000/54000 [==============================] - 5s - loss: 0.7595 - channel_loss: 0.7595 - baseline_loss: 3.7421 - channel_acc: 0.5393 - baseline_acc: 0.5369 - val_loss: 0.7953 - val_channel_loss: 0.7953 - val_baseline_loss: 3.9808 - val_channel_acc: 0.5200 - val_baseline_acc: 0.5197\n",
      "Epoch 11/40\n",
      "54000/54000 [==============================] - 5s - loss: 0.7548 - channel_loss: 0.7548 - baseline_loss: 3.8837 - channel_acc: 0.5391 - baseline_acc: 0.5379 - val_loss: 0.7902 - val_channel_loss: 0.7902 - val_baseline_loss: 4.0147 - val_channel_acc: 0.5285 - val_baseline_acc: 0.5313\n",
      "Epoch 12/40\n",
      "54000/54000 [==============================] - 6s - loss: 0.7558 - channel_loss: 0.7558 - baseline_loss: 3.9122 - channel_acc: 0.5398 - baseline_acc: 0.5393 - val_loss: 0.7857 - val_channel_loss: 0.7857 - val_baseline_loss: 4.0004 - val_channel_acc: 0.5285 - val_baseline_acc: 0.5312\n",
      "Epoch 13/40\n",
      "54000/54000 [==============================] - 5s - loss: 0.7489 - channel_loss: 0.7489 - baseline_loss: 3.9310 - channel_acc: 0.5420 - baseline_acc: 0.5402 - val_loss: 0.7842 - val_channel_loss: 0.7842 - val_baseline_loss: 4.0876 - val_channel_acc: 0.5207 - val_baseline_acc: 0.5258\n",
      "Epoch 14/40\n",
      "54000/54000 [==============================] - 6s - loss: 0.7498 - channel_loss: 0.7498 - baseline_loss: 3.9834 - channel_acc: 0.5423 - baseline_acc: 0.5396 - val_loss: 0.7825 - val_channel_loss: 0.7825 - val_baseline_loss: 4.1506 - val_channel_acc: 0.5290 - val_baseline_acc: 0.5307\n",
      "Epoch 15/40\n",
      "54000/54000 [==============================] - 7s - loss: 0.7452 - channel_loss: 0.7452 - baseline_loss: 4.0601 - channel_acc: 0.5437 - baseline_acc: 0.5415 - val_loss: 0.7817 - val_channel_loss: 0.7817 - val_baseline_loss: 4.2189 - val_channel_acc: 0.5282 - val_baseline_acc: 0.5297\n",
      "Epoch 16/40\n",
      "54000/54000 [==============================] - 6s - loss: 0.7442 - channel_loss: 0.7442 - baseline_loss: 4.1084 - channel_acc: 0.5431 - baseline_acc: 0.5401 - val_loss: 0.7844 - val_channel_loss: 0.7844 - val_baseline_loss: 4.2410 - val_channel_acc: 0.5292 - val_baseline_acc: 0.5278\n",
      "Epoch 17/40\n",
      "54000/54000 [==============================] - 6s - loss: 0.7419 - channel_loss: 0.7419 - baseline_loss: 4.1613 - channel_acc: 0.5453 - baseline_acc: 0.5414 - val_loss: 0.7859 - val_channel_loss: 0.7859 - val_baseline_loss: 4.2699 - val_channel_acc: 0.5227 - val_baseline_acc: 0.5153\n",
      "Epoch 18/40\n",
      "54000/54000 [==============================] - 6s - loss: 0.7396 - channel_loss: 0.7396 - baseline_loss: 4.1826 - channel_acc: 0.5471 - baseline_acc: 0.5445 - val_loss: 0.7858 - val_channel_loss: 0.7858 - val_baseline_loss: 4.4080 - val_channel_acc: 0.5268 - val_baseline_acc: 0.5223\n",
      "Epoch 19/40\n",
      "54000/54000 [==============================] - 6s - loss: 0.7423 - channel_loss: 0.7423 - baseline_loss: 4.2279 - channel_acc: 0.5450 - baseline_acc: 0.5426 - val_loss: 0.7835 - val_channel_loss: 0.7835 - val_baseline_loss: 4.3753 - val_channel_acc: 0.5227 - val_baseline_acc: 0.5213\n",
      "Epoch 20/40\n",
      "54000/54000 [==============================] - 6s - loss: 0.7392 - channel_loss: 0.7392 - baseline_loss: 4.2281 - channel_acc: 0.5440 - baseline_acc: 0.5416 - val_loss: 0.7820 - val_channel_loss: 0.7820 - val_baseline_loss: 4.4053 - val_channel_acc: 0.5275 - val_baseline_acc: 0.5243\n",
      "Epoch 00019: early stopping\n"
     ]
    }
   ],
   "source": [
    "train_res = simple_model.fit(X_train_train,\n",
    "                      [y_train_train,y_train_train],\n",
    "                      batch_size=batch_size,\n",
    "                      epochs=epochs,\n",
    "                      verbose=verbose,\n",
    "                      validation_data=(X_train_val,\n",
    "                                       [y_train_val,y_train_val]),\n",
    "                      callbacks=\n",
    "                      [EarlyStopping(patience=patience,mode='min',verbose=verbose)]\n",
    "                      )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'baseline_acc': 0.92569999999999997,\n",
       " 'baseline_loss': 0.24902633275985717,\n",
       " 'channel_acc': 0.94979999999999998,\n",
       " 'channel_loss': 0.67406886959075929,\n",
       " 'loss': 0.67406886959075929}"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval(simple_model,y_test=[y_test,y_test])"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
