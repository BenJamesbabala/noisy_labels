{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "FN = '170212-mnist-simple'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook we:\n",
    "* train a on MNIST in which the training labels are scrambled by a fixed permutation 46% of the time\n",
    "* The baseline 3 layer MLP model gives an accuracy of 74% on MNIST test set which was not scrambled\n",
    "* The confusion matrix of the noisy training data is computed\n",
    "* We then add a customized Keras layer ([Channel](./channel.py)) to model the noise. This layer is initialized with the log of the confusion matrix (`channel_weights`):\n",
    "```python\n",
    "channeled_output = Channel(name='channel',weights=[channel_weights])(baseline_output)\n",
    "```\n",
    "* We continue training on the new output (`channeled_output`)\n",
    "* The baseline output (`baseline_output`) has now an accuracy of 98%.\n",
    "\n",
    "For more information see the description of the [simple noise adaptation layer in the paper](https://openreview.net/forum?id=H12GRgcxg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import numpy as np\n",
    "import random\n",
    "seed = 42\n",
    "np.random.seed(seed)  # for reproducibility\n",
    "random.seed(seed)\n",
    "verbose = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# in case you dont have a GPU\n",
    "import os\n",
    "os.environ['THEANO_FLAGS'] = 'device=cpu,floatX=float32'  # Use CPU on Theano\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = ''  # Disable GPU usage on tensorflow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "nb_classes = 10 # number of categories we classify. MNIST is 10 digits\n",
    "# input image dimensions. In CNN we think we have a \"color\" image with 1 channel of color.\n",
    "# in MLP with flatten the pixels to img_rows*img_cols\n",
    "img_color, img_rows, img_cols = 1, 28, 28\n",
    "img_size = img_color*img_rows*img_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using Theano backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MNIST training data set label distribution [5923 6742 5958 6131 5842 5421 5918 6265 5851 5949]\n",
      "test distribution [ 980 1135 1032 1010  982  892  958 1028  974 1009]\n"
     ]
    }
   ],
   "source": [
    "from keras.datasets import mnist\n",
    "# keras has a built in tool that download the MNIST data set for you to `~/.keras/datasets/`\n",
    "# the data, shuffled and split between train and test sets\n",
    "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
    "print('MNIST training data set label distribution', np.bincount(y_train))\n",
    "print('test distribution', np.bincount(y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape: (60000, 784)\n",
      "60000 train samples\n",
      "10000 test samples\n"
     ]
    }
   ],
   "source": [
    "X_train = X_train.reshape(X_train.shape[0], img_size)\n",
    "X_test = X_test.reshape(X_test.shape[0], img_size)\n",
    "    \n",
    "X_train = X_train.astype('float32')\n",
    "X_test = X_test.astype('float32')\n",
    "X_train /= 255.\n",
    "X_test /= 255.\n",
    "print('X_train shape:', X_train.shape)\n",
    "print(X_train.shape[0], 'train samples')\n",
    "print(X_test.shape[0], 'test samples')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## noisy labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "NOISE_LEVEL=0.46  # what part of training labels are permuted\n",
    "perm = np.array([7, 9, 0, 4, 2, 1, 3, 5, 6, 8])  # noise permutation (from Reed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "noise = perm[y_train]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# replace some of the training labels with permuted (noise) labels.\n",
    "# make sure each categories receive an equal amount of noise\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "_, noise_idx = next(iter(StratifiedShuffleSplit(n_splits=1,\n",
    "                                                test_size=NOISE_LEVEL,\n",
    "                                                random_state=seed).split(X_train,y_train)))\n",
    "y_train_noise = y_train.copy()\n",
    "y_train_noise[noise_idx] = noise[noise_idx]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "actual noise level"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.45999999999999996"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1. - np.mean(y_train_noise == y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "split training data to training and validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# break the training set to 10% validation which we will use for early stopping.\n",
    "train_idx, val_idx = next(iter(\n",
    "        StratifiedShuffleSplit(n_splits=1, test_size=0.1,\n",
    "                               random_state=seed).split(X_train, y_train_noise)))\n",
    "X_train_train = X_train[train_idx]\n",
    "y_train_train = y_train_noise[train_idx]\n",
    "X_train_val = X_train[val_idx]\n",
    "y_train_val = y_train_noise[val_idx]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## baseline model\n",
    "We use the `Sequential` model from keras\n",
    "[mlp example](https://github.com/fchollet/keras/blob/master/examples/mnist_mlp.py)\n",
    "as a single layer which computes the last hidden layer which we then use to\n",
    "compute the baseline and as an input to the channel matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "nhiddens = [500, 300]\n",
    "DROPOUT=0.5\n",
    "opt='adam'\n",
    "batch_size = 256\n",
    "patience = 4  # Early stopping patience\n",
    "nb_epoch = 40  # number of epochs to train on"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "hidden_layers = Sequential(name='hidden')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from keras.layers import Dense, Dropout, Activation\n",
    "for i, nhidden in enumerate(nhiddens):\n",
    "    hidden_layers.add(Dense(nhidden,\n",
    "                            input_shape=(img_size,) if i == 0 else []))\n",
    "    hidden_layers.add(Activation('relu'))\n",
    "    hidden_layers.add(Dropout(DROPOUT))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from keras.layers import Input\n",
    "train_inputs = Input(shape=(img_size,))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "last_hidden = hidden_layers(train_inputs)\n",
    "baseline_output = Dense(nb_classes, activation='softmax', name='baseline')(last_hidden)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from keras.models import Model\n",
    "model = Model(input=train_inputs, output=baseline_output)\n",
    "model.compile(loss='sparse_categorical_crossentropy',\n",
    "              optimizer=opt,\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "baseline model performance evaluation before training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def eval(model,y_test=y_test):\n",
    "    return dict(zip(model.metrics_names,model.evaluate(X_test,y_test, verbose=False)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'acc': 0.1212, 'loss': 2.3552079948425293}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### baseline training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 54000 samples, validate on 6000 samples\n",
      "Epoch 1/40\n",
      "54000/54000 [==============================] - 5s - loss: 1.2520 - acc: 0.4283 - val_loss: 0.9019 - val_acc: 0.4838\n",
      "Epoch 2/40\n",
      "54000/54000 [==============================] - 5s - loss: 0.9392 - acc: 0.4828 - val_loss: 0.8414 - val_acc: 0.5058\n",
      "Epoch 3/40\n",
      "54000/54000 [==============================] - 5s - loss: 0.8767 - acc: 0.4928 - val_loss: 0.8076 - val_acc: 0.5092\n",
      "Epoch 4/40\n",
      "54000/54000 [==============================] - 5s - loss: 0.8442 - acc: 0.5008 - val_loss: 0.7948 - val_acc: 0.5000\n",
      "Epoch 5/40\n",
      "54000/54000 [==============================] - 6s - loss: 0.8199 - acc: 0.5084 - val_loss: 0.7831 - val_acc: 0.5092\n",
      "Epoch 6/40\n",
      "54000/54000 [==============================] - 5s - loss: 0.8071 - acc: 0.5114 - val_loss: 0.7772 - val_acc: 0.5037\n",
      "Epoch 7/40\n",
      "54000/54000 [==============================] - 5s - loss: 0.7958 - acc: 0.5122 - val_loss: 0.7713 - val_acc: 0.5190\n",
      "Epoch 8/40\n",
      "54000/54000 [==============================] - 6s - loss: 0.7834 - acc: 0.5188 - val_loss: 0.7706 - val_acc: 0.5063\n",
      "Epoch 9/40\n",
      "54000/54000 [==============================] - 6s - loss: 0.7797 - acc: 0.5200 - val_loss: 0.7668 - val_acc: 0.5167\n",
      "Epoch 10/40\n",
      "54000/54000 [==============================] - 6s - loss: 0.7706 - acc: 0.5186 - val_loss: 0.7622 - val_acc: 0.5102\n",
      "Epoch 11/40\n",
      "54000/54000 [==============================] - 7s - loss: 0.7672 - acc: 0.5197 - val_loss: 0.7656 - val_acc: 0.5107\n",
      "Epoch 12/40\n",
      "54000/54000 [==============================] - 6s - loss: 0.7594 - acc: 0.5263 - val_loss: 0.7602 - val_acc: 0.5190\n",
      "Epoch 13/40\n",
      "54000/54000 [==============================] - 6s - loss: 0.7565 - acc: 0.5255 - val_loss: 0.7622 - val_acc: 0.5215\n",
      "Epoch 14/40\n",
      "54000/54000 [==============================] - 7s - loss: 0.7521 - acc: 0.5309 - val_loss: 0.7619 - val_acc: 0.5177\n",
      "Epoch 15/40\n",
      "54000/54000 [==============================] - 6s - loss: 0.7490 - acc: 0.5290 - val_loss: 0.7579 - val_acc: 0.5177\n",
      "Epoch 16/40\n",
      "54000/54000 [==============================] - 6s - loss: 0.7453 - acc: 0.5316 - val_loss: 0.7656 - val_acc: 0.4985\n",
      "Epoch 17/40\n",
      "54000/54000 [==============================] - 6s - loss: 0.7410 - acc: 0.5315 - val_loss: 0.7616 - val_acc: 0.5038\n",
      "Epoch 18/40\n",
      "54000/54000 [==============================] - 6s - loss: 0.7396 - acc: 0.5314 - val_loss: 0.7602 - val_acc: 0.5115\n",
      "Epoch 19/40\n",
      "54000/54000 [==============================] - 6s - loss: 0.7353 - acc: 0.5376 - val_loss: 0.7586 - val_acc: 0.5073\n",
      "Epoch 20/40\n",
      "54000/54000 [==============================] - 6s - loss: 0.7342 - acc: 0.5347 - val_loss: 0.7604 - val_acc: 0.5133\n",
      "Epoch 00019: early stopping\n"
     ]
    }
   ],
   "source": [
    "from keras.callbacks import EarlyStopping\n",
    "train_res = model.fit(X_train_train,\n",
    "                      y_train_train,\n",
    "                      batch_size=batch_size,\n",
    "                      nb_epoch=nb_epoch,\n",
    "                      verbose=verbose,\n",
    "                      validation_data=(X_train_val,\n",
    "                                       y_train_val),\n",
    "                      callbacks=\n",
    "                      [EarlyStopping(patience=patience,mode='min',\n",
    "                                     verbose=verbose)]\n",
    "                      )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### baseline performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'acc': 0.74229999999999996, 'loss': 0.69198721151351927}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# build confusion matrix (prediction,noisy_label)\n",
    "ybaseline_predict = model.predict(X_train,batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000,)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ybaseline_predict = np.argmax(ybaseline_predict, axis=-1)\n",
    "ybaseline_predict.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "baseline_confusion = np.zeros((nb_classes, nb_classes))\n",
    "for n, p in zip(y_train_noise, ybaseline_predict):\n",
    "    baseline_confusion[p, n] += 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYYAAAEdCAYAAAAIIcBlAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\ngYiIFFgMRESk8P8BCYfP0gKIoeAAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x115913ed0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "# perm_bias_weights.astype(int)\n",
    "plt.pcolor(baseline_confusion)\n",
    "plt.ylabel('true labels')\n",
    "plt.xlabel('baseline labels')\n",
    "plt.title('baseline confusion matrix');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simple channel model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# ignore baseline loss in training\n",
    "BETA = 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "channel_weights = baseline_confusion.copy()\n",
    "channel_weights /= channel_weights.sum(axis=1, keepdims=True)\n",
    "# perm_bias_weights[prediction,noisy_label] = log(P(noisy_label|prediction))\n",
    "channel_weights = np.log(channel_weights + 1e-8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# If you dont have a pre-trained baseline model then use this\n",
    "# channel_weights = (\n",
    "#     np.array([[np.log(1. - NOISE_LEVEL)\n",
    "#                         if i == j else\n",
    "#                         np.log(NOISE / (nb_classes - 1.))\n",
    "#                         for j in range(nb_classes)] for i in\n",
    "#               range(nb_classes)])\n",
    "#     + 0.01 * np.random.random((nb_classes, nb_classes)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from channel import Channel\n",
    "channeled_output = Channel(name='channel',weights=[channel_weights])(baseline_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "simple_model = Model(input=train_inputs, output=[channeled_output, baseline_output])\n",
    "simple_model.compile(loss='sparse_categorical_crossentropy',loss_weights=[1.-BETA, BETA],\n",
    "              optimizer=opt,\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 54000 samples, validate on 6000 samples\n",
      "Epoch 1/40\n",
      "54000/54000 [==============================] - 6s - loss: 0.8480 - channel_loss: 0.8480 - baseline_loss: 1.8988 - channel_acc: 0.5352 - baseline_acc: 0.5352 - val_loss: 0.8391 - val_channel_loss: 0.8391 - val_baseline_loss: 2.3363 - val_channel_acc: 0.5327 - val_baseline_acc: 0.5318\n",
      "Epoch 2/40\n",
      "54000/54000 [==============================] - 6s - loss: 0.8118 - channel_loss: 0.8118 - baseline_loss: 2.8313 - channel_acc: 0.5359 - baseline_acc: 0.5340 - val_loss: 0.8157 - val_channel_loss: 0.8157 - val_baseline_loss: 3.1281 - val_channel_acc: 0.5315 - val_baseline_acc: 0.5323\n",
      "Epoch 3/40\n",
      "54000/54000 [==============================] - 6s - loss: 0.7946 - channel_loss: 0.7946 - baseline_loss: 3.4682 - channel_acc: 0.5354 - baseline_acc: 0.5343 - val_loss: 0.7984 - val_channel_loss: 0.7984 - val_baseline_loss: 3.7177 - val_channel_acc: 0.5325 - val_baseline_acc: 0.5327\n",
      "Epoch 4/40\n",
      "54000/54000 [==============================] - 6s - loss: 0.7785 - channel_loss: 0.7785 - baseline_loss: 3.9570 - channel_acc: 0.5359 - baseline_acc: 0.5338 - val_loss: 0.7900 - val_channel_loss: 0.7900 - val_baseline_loss: 3.9785 - val_channel_acc: 0.5322 - val_baseline_acc: 0.5325\n",
      "Epoch 5/40\n",
      "54000/54000 [==============================] - 6s - loss: 0.7687 - channel_loss: 0.7687 - baseline_loss: 4.2234 - channel_acc: 0.5358 - baseline_acc: 0.5345 - val_loss: 0.7825 - val_channel_loss: 0.7825 - val_baseline_loss: 4.4259 - val_channel_acc: 0.5343 - val_baseline_acc: 0.5338\n",
      "Epoch 6/40\n",
      "54000/54000 [==============================] - 6s - loss: 0.7609 - channel_loss: 0.7609 - baseline_loss: 4.5260 - channel_acc: 0.5351 - baseline_acc: 0.5339 - val_loss: 0.7739 - val_channel_loss: 0.7739 - val_baseline_loss: 4.7755 - val_channel_acc: 0.5348 - val_baseline_acc: 0.5342\n",
      "Epoch 7/40\n",
      "54000/54000 [==============================] - 6s - loss: 0.7571 - channel_loss: 0.7571 - baseline_loss: 4.6989 - channel_acc: 0.5358 - baseline_acc: 0.5334 - val_loss: 0.7725 - val_channel_loss: 0.7725 - val_baseline_loss: 4.9083 - val_channel_acc: 0.5333 - val_baseline_acc: 0.5333\n",
      "Epoch 8/40\n",
      "54000/54000 [==============================] - 6s - loss: 0.7552 - channel_loss: 0.7552 - baseline_loss: 4.8482 - channel_acc: 0.5353 - baseline_acc: 0.5336 - val_loss: 0.7725 - val_channel_loss: 0.7725 - val_baseline_loss: 5.0564 - val_channel_acc: 0.5328 - val_baseline_acc: 0.5330\n",
      "Epoch 9/40\n",
      "54000/54000 [==============================] - 7s - loss: 0.7474 - channel_loss: 0.7474 - baseline_loss: 5.0629 - channel_acc: 0.5355 - baseline_acc: 0.5336 - val_loss: 0.7670 - val_channel_loss: 0.7670 - val_baseline_loss: 5.2356 - val_channel_acc: 0.5320 - val_baseline_acc: 0.5320\n",
      "Epoch 10/40\n",
      "54000/54000 [==============================] - 6s - loss: 0.7413 - channel_loss: 0.7413 - baseline_loss: 5.2641 - channel_acc: 0.5355 - baseline_acc: 0.5343 - val_loss: 0.7683 - val_channel_loss: 0.7683 - val_baseline_loss: 5.4445 - val_channel_acc: 0.5340 - val_baseline_acc: 0.5330\n",
      "Epoch 11/40\n",
      "54000/54000 [==============================] - 5s - loss: 0.7394 - channel_loss: 0.7394 - baseline_loss: 5.3814 - channel_acc: 0.5370 - baseline_acc: 0.5351 - val_loss: 0.7670 - val_channel_loss: 0.7670 - val_baseline_loss: 5.4784 - val_channel_acc: 0.5322 - val_baseline_acc: 0.5323\n",
      "Epoch 12/40\n",
      "54000/54000 [==============================] - 5s - loss: 0.7379 - channel_loss: 0.7379 - baseline_loss: 5.3875 - channel_acc: 0.5359 - baseline_acc: 0.5345 - val_loss: 0.7616 - val_channel_loss: 0.7616 - val_baseline_loss: 5.6784 - val_channel_acc: 0.5340 - val_baseline_acc: 0.5335\n",
      "Epoch 13/40\n",
      "54000/54000 [==============================] - 6s - loss: 0.7358 - channel_loss: 0.7358 - baseline_loss: 5.5285 - channel_acc: 0.5362 - baseline_acc: 0.5350 - val_loss: 0.7613 - val_channel_loss: 0.7613 - val_baseline_loss: 5.6921 - val_channel_acc: 0.5347 - val_baseline_acc: 0.5333\n",
      "Epoch 14/40\n",
      "54000/54000 [==============================] - 5s - loss: 0.7323 - channel_loss: 0.7323 - baseline_loss: 5.6420 - channel_acc: 0.5366 - baseline_acc: 0.5350 - val_loss: 0.7622 - val_channel_loss: 0.7622 - val_baseline_loss: 5.7667 - val_channel_acc: 0.5313 - val_baseline_acc: 0.5328\n",
      "Epoch 15/40\n",
      "54000/54000 [==============================] - 6s - loss: 0.7322 - channel_loss: 0.7322 - baseline_loss: 5.7105 - channel_acc: 0.5361 - baseline_acc: 0.5347 - val_loss: 0.7633 - val_channel_loss: 0.7633 - val_baseline_loss: 5.8021 - val_channel_acc: 0.5330 - val_baseline_acc: 0.5330\n",
      "Epoch 16/40\n",
      "54000/54000 [==============================] - 6s - loss: 0.7307 - channel_loss: 0.7307 - baseline_loss: 5.7165 - channel_acc: 0.5363 - baseline_acc: 0.5350 - val_loss: 0.7549 - val_channel_loss: 0.7549 - val_baseline_loss: 5.9885 - val_channel_acc: 0.5338 - val_baseline_acc: 0.5330\n",
      "Epoch 17/40\n",
      "54000/54000 [==============================] - 7s - loss: 0.7280 - channel_loss: 0.7280 - baseline_loss: 5.8443 - channel_acc: 0.5368 - baseline_acc: 0.5355 - val_loss: 0.7602 - val_channel_loss: 0.7602 - val_baseline_loss: 6.0044 - val_channel_acc: 0.5323 - val_baseline_acc: 0.5322\n",
      "Epoch 18/40\n",
      "54000/54000 [==============================] - 6s - loss: 0.7274 - channel_loss: 0.7274 - baseline_loss: 5.9010 - channel_acc: 0.5362 - baseline_acc: 0.5348 - val_loss: 0.7606 - val_channel_loss: 0.7606 - val_baseline_loss: 6.0422 - val_channel_acc: 0.5332 - val_baseline_acc: 0.5327\n",
      "Epoch 19/40\n",
      "54000/54000 [==============================] - 6s - loss: 0.7249 - channel_loss: 0.7249 - baseline_loss: 5.9380 - channel_acc: 0.5368 - baseline_acc: 0.5351 - val_loss: 0.7547 - val_channel_loss: 0.7547 - val_baseline_loss: 6.1172 - val_channel_acc: 0.5342 - val_baseline_acc: 0.5342\n",
      "Epoch 20/40\n",
      "54000/54000 [==============================] - 5s - loss: 0.7249 - channel_loss: 0.7249 - baseline_loss: 5.9099 - channel_acc: 0.5370 - baseline_acc: 0.5357 - val_loss: 0.7576 - val_channel_loss: 0.7576 - val_baseline_loss: 6.1141 - val_channel_acc: 0.5340 - val_baseline_acc: 0.5337\n",
      "Epoch 21/40\n",
      "54000/54000 [==============================] - 6s - loss: 0.7216 - channel_loss: 0.7216 - baseline_loss: 6.0217 - channel_acc: 0.5370 - baseline_acc: 0.5357 - val_loss: 0.7520 - val_channel_loss: 0.7520 - val_baseline_loss: 6.2091 - val_channel_acc: 0.5338 - val_baseline_acc: 0.5338\n",
      "Epoch 22/40\n",
      "54000/54000 [==============================] - 5s - loss: 0.7192 - channel_loss: 0.7192 - baseline_loss: 6.0658 - channel_acc: 0.5375 - baseline_acc: 0.5361 - val_loss: 0.7593 - val_channel_loss: 0.7593 - val_baseline_loss: 6.3140 - val_channel_acc: 0.5333 - val_baseline_acc: 0.5332\n",
      "Epoch 23/40\n",
      "54000/54000 [==============================] - 6s - loss: 0.7225 - channel_loss: 0.7225 - baseline_loss: 6.0599 - channel_acc: 0.5372 - baseline_acc: 0.5360 - val_loss: 0.7570 - val_channel_loss: 0.7570 - val_baseline_loss: 6.3303 - val_channel_acc: 0.5338 - val_baseline_acc: 0.5335\n",
      "Epoch 24/40\n",
      "54000/54000 [==============================] - 7s - loss: 0.7227 - channel_loss: 0.7227 - baseline_loss: 6.1274 - channel_acc: 0.5375 - baseline_acc: 0.5356 - val_loss: 0.7656 - val_channel_loss: 0.7656 - val_baseline_loss: 6.2981 - val_channel_acc: 0.5325 - val_baseline_acc: 0.5323\n",
      "Epoch 25/40\n",
      "54000/54000 [==============================] - 6s - loss: 0.7215 - channel_loss: 0.7215 - baseline_loss: 6.1283 - channel_acc: 0.5365 - baseline_acc: 0.5352 - val_loss: 0.7576 - val_channel_loss: 0.7576 - val_baseline_loss: 6.3847 - val_channel_acc: 0.5340 - val_baseline_acc: 0.5335\n",
      "Epoch 26/40\n",
      "54000/54000 [==============================] - 6s - loss: 0.7201 - channel_loss: 0.7201 - baseline_loss: 6.1774 - channel_acc: 0.5367 - baseline_acc: 0.5357 - val_loss: 0.7521 - val_channel_loss: 0.7521 - val_baseline_loss: 6.3776 - val_channel_acc: 0.5327 - val_baseline_acc: 0.5332\n",
      "Epoch 00025: early stopping\n"
     ]
    }
   ],
   "source": [
    "train_res = simple_model.fit(X_train_train,\n",
    "                      [y_train_train,y_train_train],\n",
    "                      batch_size=batch_size,\n",
    "                      nb_epoch=nb_epoch,\n",
    "                      verbose=verbose,\n",
    "                      validation_data=(X_train_val,\n",
    "                                       [y_train_val,y_train_val]),\n",
    "                      callbacks=\n",
    "                      [EarlyStopping(patience=patience,mode='min',verbose=verbose)]\n",
    "                      )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'baseline_acc': 0.98250000000000004,\n",
       " 'baseline_loss': 0.085097076385761014,\n",
       " 'channel_acc': 0.98129999999999995,\n",
       " 'channel_loss': 0.68612833032608034,\n",
       " 'loss': 0.68612833032608034}"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval(simple_model,y_test=[y_test,y_test])"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
